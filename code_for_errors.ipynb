{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "76e9c9d9-3413-4a71-8e45-254dadccbfff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "from sklearn.metrics import explained_variance_score\n",
    "from sklearn.metrics import max_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from sklearn.metrics import median_absolute_error\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "826879cf-a6ce-4576-bce1-b77d623165b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split(df: pd.DataFrame, n: int = 2) -> list:\n",
    "    return np.array_split(df, n)\n",
    "\n",
    "\n",
    "def blend_and_split(df: pd.DataFrame, n: int = 2, frac: int = 0.5, seed: int = 42) -> list:\n",
    "    return list(df.sample(frac=frac, replace=True, random_state=seed) for i in range(0, n))\n",
    "\n",
    "\n",
    "def init_svm():\n",
    "    return SVR(kernel=\"rbf\")\n",
    "\n",
    "\n",
    "def init_sgd():\n",
    "    return SGDRegressor(loss='squared_loss', alpha=0.0001)\n",
    "\n",
    "\n",
    "def init_dnn():\n",
    "    # TODO: implement\n",
    "    raise Exception(f'Not implemented')\n",
    "\n",
    "\n",
    "def init_model(model_type):\n",
    "    \"\"\"\n",
    "    :param model_type: 'svm', 'neural_network'\n",
    "    :return: model instance\n",
    "    \"\"\"\n",
    "    # вибір типу та ініціалізація моделі\n",
    "    if model_type == 'svm':\n",
    "        model = init_svm()\n",
    "    elif model_type == 'sgd':\n",
    "        model = init_sgd()\n",
    "    elif model_type == 'dnn':\n",
    "        model = init_dnn()\n",
    "    else:\n",
    "        raise Exception(f'Unknown model type: {model_type}')\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def init_metrics():\n",
    "    return {\n",
    "        'train': {\n",
    "            'explained_variance_score': [],\n",
    "            'max_error': [],\n",
    "            'mean_absolute_error': [],\n",
    "            'mean_squared_error': [],\n",
    "            'root_mean_squared_error': [],\n",
    "            'mean_absolute_percentage_error': [],\n",
    "            'median_absolute_error': [],\n",
    "            'r2_score': []\n",
    "        },\n",
    "        'test': {\n",
    "            'explained_variance_score': [],\n",
    "            'max_error': [],\n",
    "            'mean_absolute_error': [],\n",
    "            'mean_squared_error': [],\n",
    "            'root_mean_squared_error': [],\n",
    "            'mean_absolute_percentage_error': [],\n",
    "            'median_absolute_error': [],\n",
    "            'r2_score': []\n",
    "        }\n",
    "    }\n",
    "\n",
    "def calc_train_metrics(metrics, train_y, train_pred):\n",
    "    metrics['train']['explained_variance_score'].append(explained_variance_score(train_y, train_pred))\n",
    "    metrics['train']['max_error'].append(max_error(train_y, train_pred))\n",
    "    metrics['train']['mean_absolute_error'].append(mean_absolute_error(train_y, train_pred))\n",
    "    metrics['train']['mean_squared_error'].append(mean_squared_error(train_y, train_pred, squared=True))\n",
    "    metrics['train']['root_mean_squared_error'].append(mean_squared_error(train_y, train_pred, squared=False))\n",
    "    metrics['train']['mean_absolute_percentage_error'].append(mean_absolute_percentage_error(train_y, train_pred)*100)\n",
    "    metrics['train']['median_absolute_error'].append(median_absolute_error(train_y, train_pred))\n",
    "    metrics['train']['r2_score'].append(r2_score(train_y, train_pred))\n",
    "    \n",
    "def calc_test_metrics(metrics, test_y, test_pred):\n",
    "    metrics['test']['explained_variance_score'].append(explained_variance_score(test_y, test_pred))\n",
    "    metrics['test']['max_error'].append(max_error(test_y, test_pred))\n",
    "    metrics['test']['mean_absolute_error'].append(mean_absolute_error(test_y, test_pred))\n",
    "    metrics['test']['mean_squared_error'].append(mean_squared_error(test_y, test_pred, squared=True))\n",
    "    metrics['test']['root_mean_squared_error'].append(mean_squared_error(test_y, test_pred, squared=False))\n",
    "    metrics['test']['mean_absolute_percentage_error'].append(mean_absolute_percentage_error(test_y, test_pred)*100)\n",
    "    metrics['test']['median_absolute_error'].append(median_absolute_error(test_y, test_pred))\n",
    "    metrics['test']['r2_score'].append(r2_score(test_y, test_pred))\n",
    "    \n",
    "def scale(scaler, train_X, test_X):\n",
    "    scaler.fit(train_X)\n",
    "\n",
    "    train_X = pd.DataFrame(scaler.transform(train_X))\n",
    "    test_X = pd.DataFrame(scaler.transform(test_X))\n",
    "\n",
    "    return train_X, test_X\n",
    "\n",
    "def add_poly_features(poly, train_X, test_X):\n",
    "    train_X = pd.DataFrame(poly.fit_transform(train_X))\n",
    "    test_X  = pd.DataFrame(poly.fit_transform(test_X))\n",
    "\n",
    "    return train_X, test_X\n",
    "\n",
    "def print_pretty(d, indent=0):\n",
    "    for key, value in d.items():\n",
    "        print('\\t' * indent + str(key))\n",
    "        if isinstance(value, dict):\n",
    "            print_pretty(value, indent+1)\n",
    "        else:\n",
    "            print('\\t' * (indent+2) + str(value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "45f77a67-50f4-41ea-9112-14757740f06b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(model_type:      str,  # 'dnn'\n",
    "                   train_datasets:  list,\n",
    "                   test_dataset:    pd.DataFrame,\n",
    "                   n_pfeatures:     int,  # 0 -> do not generate polynomial features\n",
    "                   export_to_excel: bool=True,\n",
    "                   keep_last:       bool=True):\n",
    "    \n",
    "    \"\"\"\n",
    "    Note: number of cascades is set implicitly by the number of train data sets\n",
    "    \"\"\"\n",
    "    if n_pfeatures > 0:\n",
    "        poly = PolynomialFeatures(n_pfeatures)\n",
    "    test_preds = []\n",
    "    metrics = init_metrics()\n",
    "    models = []\n",
    "\n",
    "    for cascade in range(len(train_datasets)):\n",
    "        print(f'cascade-{cascade}')\n",
    "        train_dataset = train_datasets[cascade].copy()\n",
    "        test_dataset_loc = test_dataset.copy()\n",
    "        train_X = train_dataset.iloc[:, :-1]\n",
    "        train_y = train_dataset.iloc[:,-1]\n",
    "        test_X = test_dataset_loc.iloc[:, :-1]\n",
    "        test_y = test_dataset_loc.iloc[:,-1]\n",
    "        test_y_hist = test_dataset_loc.iloc[:,-1]\n",
    "        model = init_model(model_type)\n",
    "        \n",
    "        # генеруємо і додаємо y_pred_i до фіч\n",
    "        for i in range(cascade):\n",
    "            train_X_alt = train_X.copy()\n",
    "            test_X_alt = test_X.copy()\n",
    "            \n",
    "            if n_pfeatures > 0:\n",
    "                train_X_alt, test_X_alt = add_poly_features(poly, train_X_alt, test_X_alt)\n",
    "            train_X_alt, test_X_alt = scale(MinMaxScaler(), train_X_alt, test_X_alt)\n",
    "            \n",
    "            if keep_last:\n",
    "                train_X['y_pred'] = models[i].predict(train_X_alt)\n",
    "                test_X['y_pred'] = models[i].predict(test_X_alt)\n",
    "            else:\n",
    "                train_X[f'y_pred_{i+1}'] = models[i].predict(train_X_alt)\n",
    "                test_X[f'y_pred_{i+1}'] = models[i].predict(test_X_alt)\n",
    "        \n",
    "        if n_pfeatures > 0:\n",
    "            train_X, test_X = add_poly_features(poly, train_X, test_X)\n",
    "        train_X, test_X = scale(MinMaxScaler(), train_X, test_X)\n",
    "        \n",
    "        model.fit(train_X, train_y)\n",
    "        models.append(model)\n",
    "\n",
    "        # рахуємо та зберігаємо метрики\n",
    "        test_pred = model.predict(test_X)\n",
    "        calc_train_metrics(metrics, train_y, model.predict(train_X))\n",
    "        calc_test_metrics(metrics, test_y, test_pred)\n",
    "        test_preds.append(test_pred)\n",
    "    \n",
    "    if export_to_excel:\n",
    "        date_time_now = datetime.datetime.now()\n",
    "        metrics_train_df = pd.DataFrame(data=metrics['train'])\n",
    "        metrics_train_df.index.name = 'cascade'\n",
    "        metrics_test_df = pd.DataFrame(data=metrics['test'])\n",
    "        metrics_test_df.index.name = 'cascade'\n",
    "        test_preds_df = pd.DataFrame(data=test_preds)\n",
    "        \n",
    "        with pd.ExcelWriter( 'experiment-run-{date_time_now}.xlsx') as writer:  \n",
    "            metrics_train_df.to_excel(writer, sheet_name='train')\n",
    "            metrics_test_df.to_excel(writer, sheet_name='test')\n",
    "            test_preds_df.T.to_excel(writer, sheet_name='test-preds')\n",
    "        \n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7ade51a-2475-4e8d-aa46-65dddb1abcec",
   "metadata": {},
   "source": [
    "# Experiment 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "acd4fc16-6864-4ed1-903b-114aa8961f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train = pd.read_csv('trainCO.txt', header=None)\n",
    "# df_test = pd.read_csv('testCO.txt', header=None)\n",
    "df_train = pd.read_csv('c:/Users/ivani/Documents/sgtm/Datasets/heart_train.txt', header=None)\n",
    "df_test = pd.read_csv('c:/Users/ivani/Documents/sgtm/Datasets/heart_test.txt', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae3bf05d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b3846001-9a7e-47a5-8d4d-01bb280821f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "\texplained_variance_score\n",
      "\t\t\t[0.9931599660082169]\n",
      "\tmax_error\n",
      "\t\t\t[6.521206145553137]\n",
      "\tmean_absolute_error\n",
      "\t\t\t[0.5671231378695447]\n",
      "\tmean_squared_error\n",
      "\t\t\t[0.7382032007190803]\n",
      "\troot_mean_squared_error\n",
      "\t\t\t[0.8591875236053421]\n",
      "\tmean_absolute_percentage_error\n",
      "\t\t\t[0.7734857774470688]\n",
      "\tmedian_absolute_error\n",
      "\t\t\t[0.3855299530129237]\n",
      "\tr2_score\n",
      "\t\t\t[0.9930667444613798]\n",
      "test\n",
      "\texplained_variance_score\n",
      "\t\t\t[0.9931894413043391]\n",
      "\tmax_error\n",
      "\t\t\t[6.495123015513073]\n",
      "\tmean_absolute_error\n",
      "\t\t\t[0.5680881770731935]\n",
      "\tmean_squared_error\n",
      "\t\t\t[0.7435188245203438]\n",
      "\troot_mean_squared_error\n",
      "\t\t\t[0.862275376269289]\n",
      "\tmean_absolute_percentage_error\n",
      "\t\t\t[0.7723408811818248]\n",
      "\tmedian_absolute_error\n",
      "\t\t\t[0.3852667542737862]\n",
      "\tr2_score\n",
      "\t\t\t[0.9931005912498252]\n"
     ]
    }
   ],
   "source": [
    "train_X = df_train.iloc[:, :-1]\n",
    "train_y = df_train.iloc[:,-1]\n",
    "test_X = df_test.iloc[:, :-1]\n",
    "test_y = df_test.iloc[:,-1]\n",
    "\n",
    "metrics = init_metrics()\n",
    "poly = PolynomialFeatures(2)\n",
    "train_X, test_X = add_poly_features(poly, train_X, test_X)\n",
    "train_X, test_X = scale(MinMaxScaler(), train_X, test_X)\n",
    "model = init_model('sgd')\n",
    "\n",
    "model.fit(train_X, train_y)\n",
    "\n",
    "calc_train_metrics(metrics, train_y, model.predict(train_X))\n",
    "calc_test_metrics(metrics, test_y, model.predict(test_X))\n",
    "\n",
    "print_pretty(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d88fa2d-d9e6-47bf-820f-c43f5c96b9d0",
   "metadata": {},
   "source": [
    "## Plain Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d2be97e4-8b60-4883-a5c4-7f1b6d1c6e0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len train_split_plain: 5\n",
      "cascade-0\n",
      "cascade-1\n",
      "cascade-2\n",
      "cascade-3\n",
      "cascade-4\n",
      "train\n",
      "\texplained_variance_score\n",
      "\t\t\t[0.9899877027859189, 0.997485900993333, 0.9977109710641106, 0.9976870245047024, 0.9976625684748894]\n",
      "\tmax_error\n",
      "\t\t\t[7.68661200273813, 8.14573647422418, 6.494146300992114, 5.920829597661566, 6.138576572441124]\n",
      "\tmean_absolute_error\n",
      "\t\t\t[0.6788192825829829, 0.3436198443255379, 0.32731204087839294, 0.33383917587611195, 0.3353535282405324]\n",
      "\tmean_squared_error\n",
      "\t\t\t[1.0555388758557678, 0.2685679667771005, 0.24484040681309396, 0.24749095371526764, 0.24917448319644647]\n",
      "\troot_mean_squared_error\n",
      "\t\t\t[1.0273942163822842, 0.5182354356632712, 0.4948135071045393, 0.4974846266119865, 0.499173800590983]\n",
      "\tmean_absolute_percentage_error\n",
      "\t\t\t[0.925742797646738, 0.45965831361157605, 0.4374548228094446, 0.4480740140737604, 0.449326533272543]\n",
      "\tmedian_absolute_error\n",
      "\t\t\t[0.46464022035887353, 0.2414481765620664, 0.22580480553735427, 0.22902049307607797, 0.23074238510374556]\n",
      "\tr2_score\n",
      "\t\t\t[0.989987669435303, 0.9974776684258193, 0.9977098566935486, 0.9976858018645803, 0.9976625577166262]\n",
      "test\n",
      "\texplained_variance_score\n",
      "\t\t\t[0.9899245899712501, 0.9974648568198505, 0.9976978596813715, 0.9977078387387511, 0.9976514310871631]\n",
      "\tmax_error\n",
      "\t\t\t[7.654741019168441, 9.449348222042204, 6.507962113665371, 5.915901390752779, 6.248173513457999]\n",
      "\tmean_absolute_error\n",
      "\t\t\t[0.6845162390267252, 0.3459415037727572, 0.32982676795278587, 0.3317937529967548, 0.33628394859929395]\n",
      "\tmean_squared_error\n",
      "\t\t\t[1.0858031030923077, 0.27382307150225604, 0.24832429067290882, 0.24724008286528687, 0.25310210281380946]\n",
      "\troot_mean_squared_error\n",
      "\t\t\t[1.0420187633110585, 0.5232810635808026, 0.4983214732207602, 0.4972324233849668, 0.5030925390162425]\n",
      "\tmean_absolute_percentage_error\n",
      "\t\t\t[0.9269488878484472, 0.4619192367673853, 0.44033676953292566, 0.4443181751652905, 0.44924910156557746]\n",
      "\tmedian_absolute_error\n",
      "\t\t\t[0.4642588897563087, 0.2428120536696241, 0.22625273994398754, 0.2263064872085252, 0.2322278735543648]\n",
      "\tr2_score\n",
      "\t\t\t[0.9899243984370203, 0.9974590861277236, 0.9976956995203788, 0.9977057603185566, 0.9976513642893067]\n",
      "Wall time: 1min 40s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "train_split_plain = split(df_train, n=5)\n",
    "\n",
    "print('len train_split_plain:', len(train_split_plain))\n",
    "\n",
    "metrics = run_experiment(model_type = 'sgd', # TODO: 'dnn'\n",
    "                         train_datasets = train_split_plain,\n",
    "                         test_dataset = df_test,\n",
    "                         n_pfeatures = 2)\n",
    "print_pretty(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0a3d18f-7cfc-498f-9e47-23703feab8e3",
   "metadata": {},
   "source": [
    "## Blended Split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2694d412-9bd8-46da-83a2-167607482e79",
   "metadata": {},
   "source": [
    "# Experiment 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2b07c5b-0068-4be0-b059-675cc5898c3c",
   "metadata": {},
   "source": [
    "## Baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c0e6a39-6002-45dd-8c12-ab3b46c9cc28",
   "metadata": {},
   "source": [
    "## Plain Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0684c8bb-10e4-4017-802a-16ae1a4149a3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
